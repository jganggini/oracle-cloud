{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f64e082",
   "metadata": {},
   "source": [
    "# Data Pipeline In Data Flow: Read Parquet to Bucket\n",
    "\n",
    "Data Flow Integration with Data Science uses [oci](https://docs.oracle.com/en-us/iaas/data-flow/using/data-flow-studio.htm) environments to manage python dependencies.\n",
    "\n",
    "> https://docs.oracle.com/en-us/iaas/data-flow/using/data-flow-studio.htm\n",
    "\n",
    "[![Notebook Examples](https://img.shields.io/badge/docs-notebook--examples-blue)](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/master/notebook_examples)\n",
    "[![Conda Environments](https://img.shields.io/badge/docs-conda--environments-blue)](https://docs.oracle.com/en-us/iaas/data-science/using/conda_understand_environments.htm)\n",
    "[![Source Code](https://img.shields.io/badge/source-accelerated--datascience-blue)](https://github.com/oracle/accelerated-data-science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0050e11-1a23-42e2-9c76-3e6e5c8a43c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(\"resource_principal\") # Supported values: resource_principal, api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc880ce-c67b-4152-ae1a-8216a68d2e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7285c7e9-df35-4a9c-8287-bc04db4992d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the Cluster..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff0fb233e94489dbaab909c40180710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster is ready..\n",
      "Starting Spark application..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>Session ID</th><th>Kind</th><th>State</th><th>Current session</th></tr><tr><td>ocid1.dataflowapplication.oc1.iad.anuwcljtfioir7ia7mo7xvdufnb7jvmqgkt2bsd72zsinhtzmtzgyqd3bd7q</td><td>pyspark</td><td>IN_PROGRESS</td><td><a target=\"_blank\" href=\"https://console.us-phoenix-1.oraclecloud.com/data-flow/runs/details/ocid1.dataflowrun.oc1.iad.anuwcljtfioir7ia2dk7yfkfgifjftmeqlowyxfhjbxcisty6u52353i4yaa?region=us-ashburn-1\">Dataflow Run</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "SparkContext available as 'sc'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "command = {\n",
    "    \"compartmentId\": \"ocid1.compartment.oc1..************************************************************\",\n",
    "    \"displayName\": \"data-science-data-flow-data-frame-spark\",\n",
    "    \"language\": \"PYTHON\",\n",
    "    \"sparkVersion\": \"3.2.1\",\n",
    "    \"driverShape\": \"VM.Standard.E3.Flex\",\n",
    "    \"executorShape\": \"VM.Standard.E3.Flex\",\n",
    "    \"driverShapeConfig\":{\"ocpus\":4,\"memoryInGBs\":16},\n",
    "    \"executorShapeConfig\":{\"ocpus\":4,\"memoryInGBs\":16},\n",
    "    \"numExecutors\": 1,\n",
    "    \"type\": \"SESSION\",\n",
    "    \"logsBucketUri\": \"oci://DLK1LAG@*********/dataflow-logs\",\n",
    "}\n",
    "command = f'\\'{json.dumps(command)}\\''\n",
    " \n",
    "%create_session -l python -c $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee81002-1b3c-4ad1-8e56-a965c511194d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   10000|\n",
      "+--------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_customer_demo = spark.read.parquet(\"oci://DLK1LAG@*********/CUSTOMER_DEMO/\")\n",
    "df_customer_demo.createOrReplaceTempView(\"CUSTOMER_DEMO\")\n",
    "\n",
    "# SQL Query on Temporary View\n",
    "df = spark.sql(\"SELECT count(1) FROM CUSTOMER_DEMO\")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v3]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
