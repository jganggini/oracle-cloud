{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27038c1b-84b8-41de-89a1-5071e3950eb7",
   "metadata": {},
   "source": [
    "# Data Pipeline in Data Flow: Copy Data From ADW to Bucket\n",
    "\n",
    "Data Flow Integration with Data Science uses [oci](https://docs.oracle.com/en-us/iaas/data-flow/using/data-flow-studio.htm) environments to manage python dependencies.\n",
    "\n",
    "> https://docs.oracle.com/es-ww/iaas/data-flow/using/spark_oracle_datasource.htm\n",
    "\n",
    "[![Notebook Examples](https://img.shields.io/badge/docs-notebook--examples-blue)](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/master/notebook_examples)\n",
    "[![Conda Environments](https://img.shields.io/badge/docs-conda--environments-blue)](https://docs.oracle.com/en-us/iaas/data-science/using/conda_understand_environments.htm)\n",
    "[![Source Code](https://img.shields.io/badge/source-accelerated--datascience-blue)](https://github.com/oracle/accelerated-data-science)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8154ef-b09e-438a-b5f1-ab6ff9d21af2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### [Step 1] Libraries & Authentication and Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0050e11-1a23-42e2-9c76-3e6e5c8a43c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import oci\n",
    "import ads\n",
    "\n",
    "import json\n",
    "\n",
    "# Supported values: resource_principal, api_key\n",
    "ads.set_auth(\"resource_principal\") \n",
    "signer = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "# Config\n",
    "config = {'region': signer.region, 'tenancy': signer.tenancy_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e363236-8682-4792-96f9-f52530a7cf91",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### [Step 2] [Python]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcf593-01f4-40be-b012-41939939051f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 2.1] [Python] Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4f0a34-28c6-44d0-8f04-6267f574665a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Compartment ID\n",
    "compartment_id   = \"ocid1.compartment.oc1..************************************************************\"\n",
    "# Enter Display Name\n",
    "display_name     = \"data-science-data-flow-adb-export-data-spark\"\n",
    "\n",
    "# Enter your Namespace\n",
    "namespace        = \"************\"\n",
    "# Enter your Object storage: Bucket Name\n",
    "bucket_name      = \"DLK1LAG\"\n",
    "# Enter Folder Name\n",
    "folder_name      = \"CUSTOMER_DEMO\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad151060-254d-4f14-b602-92c884152251",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 2.2] [Python] Delete Object (Folder) in Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bdc760-80f2-4dc6-9a45-860f35be5abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn_delete_object_bucket(namespace, bucket_name, folder_name):\n",
    "    # Create the Object Storage client using the ADS signer\n",
    "    object_storage_client = oci.object_storage.ObjectStorageClient(config, signer=signer)\n",
    "        \n",
    "    try:\n",
    "        object_storage_client.delete_object(namespace, bucket_name, f\"{folder_name}/\")\n",
    "        print(f\"Folder /'{folder_name}', deleted successfully from OCI Object Storage bucket '{bucket_name}'.\")\n",
    "    \n",
    "    # Capture specific OCI errors\n",
    "    except oci.exceptions.ServiceError as e:\n",
    "        if e.status == 404 and e.code == 'ObjectNotFound':\n",
    "            print(f\"Error: The folder /'{folder_name}', does not exist in bucket '{bucket_name}'. Nothing to delete.\")\n",
    "        else:\n",
    "            print(\"OCI Service Error:\", str(e))\n",
    "    \n",
    "    # Catch other errors\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e3126-daf6-45ee-8532-05bc4e730fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 2.3] [Python] Starting Data Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8ea8a8-79c7-4982-bac1-980690d982ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn_get_data_flow_application_id(display_name):\n",
    "    # Crear un cliente para el servicio Data Flow\n",
    "    data_flow_client = oci.data_flow.DataFlowClient(config, signer=signer)\n",
    "    \n",
    "    # List executions in Data Flow\n",
    "    list_runs_response = data_flow_client.list_runs(compartment_id=compartment_id, sort_order=\"DESC\")    \n",
    "\n",
    "    # Filtrar los registros donde lifecycle_state es 'IN_PROGRESS' and display_name\n",
    "    in_progress_runs = [run for run in list_runs_response.data if run.lifecycle_state == 'IN_PROGRESS' and run.display_name == display_name]\n",
    "    \n",
    "    # Return the application id if it exists\n",
    "    try:\n",
    "        application_id = in_progress_runs[0].application_id\n",
    "        return application_id\n",
    "    \n",
    "    # Catch other errors\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc880ce-c67b-4152-ae1a-8216a68d2e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Magics Extension for Data Flow\n",
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f904e57-d1bc-4a90-b305-559af1446b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the Cluster..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f543855744342aba23a2cd0f37d3461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster is ready..\n",
      "Starting Spark application..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>Session ID</th><th>Kind</th><th>State</th><th>Current session</th></tr><tr><td>ocid1.dataflowapplication.oc1.iad.anuwcljrfioir7iacyfk7xyqaduam7v23ep2yimyibeqp7lgrt2ybm5onu6a</td><td>pyspark</td><td>IN_PROGRESS</td><td><a target=\"_blank\" href=\"https://console.us-phoenix-1.oraclecloud.com/data-flow/runs/details/ocid1.dataflowrun.oc1.iad.anuwcljrfioir7ia4b6tqx2x7r5qvbqlu35al2rq5bjoh47hjgeatqknbn5q?region=us-ashburn-1\">Dataflow Run</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "SparkContext available as 'sc'.\n"
     ]
    }
   ],
   "source": [
    "# Application Id\n",
    "application_id        = fn_get_data_flow_application_id(display_name)\n",
    "\n",
    "if application_id:\n",
    "    # Use Variable Directly in Python Code\n",
    "    command = f\"%use_session -s {application_id}\"\n",
    "    get_ipython().run_line_magic('use_session', f\"-s {application_id}\")\n",
    "else:\n",
    "    command = {\n",
    "        \"compartmentId\": \"ocid1.compartment.oc1..************************************************************\",\n",
    "        \"displayName\": display_name,\n",
    "        \"language\": \"PYTHON\",\n",
    "        \"sparkVersion\": \"3.2.1\",\n",
    "        \"driverShape\": \"VM.Standard.E3.Flex\",\n",
    "        \"executorShape\": \"VM.Standard.E3.Flex\",\n",
    "        \"driverShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16},\n",
    "        \"executorShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16},\n",
    "        \"numExecutors\": 6,\n",
    "        \"type\": \"SESSION\",\n",
    "        \"logsBucketUri\": f\"oci://{bucket_name}@{namespace}/dataflow-logs\",\n",
    "        \"configuration\": {\n",
    "            \"spark.oracle.datasource.enabled\":\"true\"\n",
    "        }\n",
    "    }\n",
    "    # Convert the configuration to JSON and pass it as a string to the magic command\n",
    "    json_command = json.dumps(command)\n",
    "    # Using line magic with the appropriate arguments\n",
    "    get_ipython().run_line_magic('create_session', f\"-l python -c '{json_command}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18615f6-5eed-45da-8890-7b8f289c6bcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### [Step 3] [Data Flow]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35fdce-2aa6-4e1e-9dd6-f421b00b604d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 3.1] [Data Flow] Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea906f73-fe14-40f9-8a08-e2f65817abd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "# Enter your Namespace\n",
    "namespace        = \"************\"\n",
    "# Enter your Object storage: Bucket Name\n",
    "bucket_name      = \"DLK1LAG\"\n",
    "\n",
    "# Autonomous DB\n",
    "walletUri        = f\"oci://{bucket_name}@{namespace}/Wallet_ADWDEMO.zip\"\n",
    "connectionId     = \"adwdemo_high\"\n",
    "user             = \"admin\"\n",
    "password         = \"************\"\n",
    "\n",
    "# Schema.Table\n",
    "schema_name      = \"ADMIN\"\n",
    "table_name       = \"CUSTOMER_DEMO\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b714fa-bdaf-4d93-8e94-eeaef3a3d515",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 3.2] [Data Flow] Get Partitions Autononous DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c01d060-647a-4e02-ab94-e75681aa4477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "def fn_get_partitions_adb(schema_name, table_name, walletUri, connectionId, user, password):\n",
    "    # Consulta para obtener los nombres de las particiones\n",
    "    query = f\"(SELECT PARTITION_NAME FROM DBA_TAB_PARTITIONS WHERE table_owner = '{schema_name}' AND table_name = '{table_name}')\"\n",
    "\n",
    "    # Ejecutar la consulta y obtener una lista de nombres de particiones\n",
    "    df_partitions = spark.read \\\n",
    "        .format(\"oracle\") \\\n",
    "        .option(\"walletUri\", walletUri) \\\n",
    "        .option(\"connectionId\", connectionId) \\\n",
    "        .option(\"dbtable\", query) \\\n",
    "        .option(\"user\", user) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .load()\n",
    "\n",
    "    # Convertir el DataFrame de nombres de particiones a una lista\n",
    "    return [row['PARTITION_NAME'] for row in df_partitions.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db765ad-b276-47c0-a165-6f9f0be4715b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 3.3] [Data Flow] Get Partitions from a Table in Autonomous DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33f17a-52cb-46f0-887c-574ec4f847dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def fn_get_partitions_table_adb(schema_name, table_name, walletUri, connectionId, user, password):\n",
    "    # List to store temporary DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Partition\n",
    "    for partition in partitions:\n",
    "        # Query by table\n",
    "        query = f\"(SELECT * FROM {schema_name}.{table_name} PARTITION({partition}))\"    \n",
    "        \n",
    "        df_partition = spark.read \\\n",
    "            .format(\"oracle\") \\\n",
    "            .option(\"walletUri\", walletUri) \\\n",
    "            .option(\"connectionId\", connectionId) \\\n",
    "            .option(\"dbtable\", query) \\\n",
    "            .option(\"user\", user) \\\n",
    "            .option(\"password\", password) \\\n",
    "            .load()\n",
    "\n",
    "        # Add the DataFrame to the list\n",
    "        dfs.append(df_partition)\n",
    "\n",
    "    # Join all DataFrames into one\n",
    "    df = reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "    # Persist the merged DataFrame in memory\n",
    "    df.persist()\n",
    "\n",
    "    # Force data to be loaded into memory\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6adf21-fdc1-4b9e-98ca-b1f5b63564a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### [Step 2.4] [Data Flow] Send Data to Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff3db228-08c8-459a-8796-742d94634d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "def fn_export_dataframe_to_bucket(namespace, bucket_name, table_name, df):\n",
    "    # Adjust and Observe Performance\n",
    "    df = df.repartition(100)\n",
    "\n",
    "    # Write Dataframe to Bucket\n",
    "    df.write \\\n",
    "        .option(\"compression\", \"snappy\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(f\"oci://{bucket_name}@{namespace}/{table_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb67a6-57eb-4043-a7b3-f2733495c7c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [Step 4] Data Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58922cd2-7f8a-41e6-9297-502575142de1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### [Step 4.1] [Data Processing] [Python] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9662cb-356b-44cc-b9f5-a1e5319afb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'CUSTOMER_DEMO/' deleted successfully from OCI Object Storage bucket 'DLK1LAG'.\n"
     ]
    }
   ],
   "source": [
    "fn_delete_object_bucket(namespace, bucket_name, folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53dc397-907f-4ab1-92d9-0b7324337694",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### [Step 4.2] [Data Processing] [Spark] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0baaa2d-16e6-4de2-988f-ee3946bd22b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P_202202', 'P_202310', 'P_202205', 'P_202106', 'P_202402', 'P_202405', 'P_202104', 'P_202210', 'P_202112', 'P_202108', 'P_202408', 'P_202005', 'P_202306', 'P_202002', 'P_202312', 'P_202406', 'P_202010', 'P_202412', 'P_202201', 'P_202309', 'P_202209', 'P_202109', 'P_202001', 'P_202304', 'P_202111', 'P_202401', 'P_202211', 'P_202411', 'P_202409', 'P_202007', 'P_202012', 'P_202206', 'P_202203', 'P_202404', 'P_202003', 'P_202303', 'P_202103', 'P_202305', 'P_202403', 'P_202110', 'P_202207', 'P_202004', 'P_202407', 'P_202311', 'P_202410', 'P_202011', 'P_202307', 'P_202009', 'P_202302', 'P_202102', 'P_202101', 'P_202308', 'P_202006', 'P_202208', 'P_202212', 'P_202301', 'P_202105', 'P_202204', 'P_202008', 'P_202107', 'P_202501', 'P_202502', 'P_202503', 'P_202504', 'P_202505', 'P_202506', 'P_202507', 'P_202508', 'P_202509', 'P_202510', 'P_202511', 'P_202512']"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "par = fn_get_partitions_adb(schema_name, table_name, walletUri, connectionId, user, password)\n",
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc9345-877e-485c-92b0-51fb2e0a2e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df = fn_get_partitions_table_adb(schema_name, table_name, walletUri, connectionId, user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95696f89-7704-47d8-b922-49ef1bdcf608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "fn_export_dataframe_to_bucket(namespace, bucket_name, table_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1c165-e06a-44c1-b3a8-db82b4f28fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-------------+--------------------+-------------+--------------------+--------------------+--------------------+------------+--------------------+------------+------------+----------------------+\n",
      "|        CUSTOMER_ID|   REGISTRATION_DATE|   MODIFICATION_DATE|CUSTOMER_CODE|       DOCUMENT_CODE|DOCUMENT_TYPE|          FIRST_NAME|           LAST_NAME|          BIRTH_DATE|      GENDER|               EMAIL|      STATUS|PHONE_NUMBER|LAST_MODIFICATION_DATE|\n",
      "+-------------------+--------------------+--------------------+-------------+--------------------+-------------+--------------------+--------------------+--------------------+------------+--------------------+------------+------------+----------------------+\n",
      "|25040773.0000000000|2024-04-15 19:42:...|2024-04-15 19:42:...|   LSZYCPUUSQ|PZQJC35Z0P40LM10F...| 4.0000000000|ktmEgQnehmcXrEFDM...|syLCTDKhntDOyKzip...|2016-02-01 09:46:...|1.0000000000|lBmHRhDpLG@exampl...|1.0000000000|  LBZTLSMKZX|  2022-02-06 15:51:...|\n",
      "|25040795.0000000000|2024-04-15 19:42:...|2024-04-15 19:42:...|   GTSVUOMORG|HOSAHH03BJK7CHY11...| 3.0000000000|EqsBrWNgxPgHdZGkS...|HulAwkwyjBmirEhXe...|2002-05-16 23:42:...|1.0000000000|vaZZMgpbCJ@exampl...|1.0000000000|  YQOPXTCRTC|  2022-02-19 18:59:...|\n",
      "|25040804.0000000000|2024-04-15 19:42:...|2024-04-15 19:42:...|   AXPYHHOGGD|B9OUVKJE4HHAUG5FK...| 3.0000000000|pdAWblghaBrwNajsW...|CasGYpLxUFGrTiUXx...|1975-08-12 06:19:...|1.0000000000|gyNShJgyca@exampl...|       0E-10|  GLPYVRAXEM|  2022-02-22 21:04:...|\n",
      "|25040977.0000000000|2024-04-15 19:42:...|2024-04-15 19:42:...|   PTPWDHTIEC|HWV39KTYJWHJN8V2C...| 3.0000000000|toIacIoyZzyqRnPrg...|PbNjyeMiVPcmcQZaB...|1998-12-23 09:05:...|1.0000000000|carNsbfyyA@exampl...|       0E-10|  IRJQKMUIYI|  2022-02-05 07:52:...|\n",
      "|25040999.0000000000|2024-04-15 19:42:...|2024-04-15 19:42:...|   HWYRXYGGQS|ZRMBD0JVGNDUXWHVG...| 3.0000000000|ioINUwlHFKUpDRDlm...|YXdvSBUATFWcLwTZc...|1980-03-03 13:36:...|2.0000000000|gnqqnFqjNg@exampl...|       0E-10|  ZGAQIZOJFC|  2022-02-14 06:22:...|\n",
      "+-------------------+--------------------+--------------------+-------------+--------------------+-------------+--------------------+--------------------+--------------------+------------+--------------------+------------+------------+----------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "# See the First 5 Results of the Dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cd0ee-7666-481e-9b6d-394ea7158883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[CUSTOMER_ID: decimal(38,10), REGISTRATION_DATE: timestamp, MODIFICATION_DATE: timestamp, CUSTOMER_CODE: string, DOCUMENT_CODE: string, DOCUMENT_TYPE: decimal(38,10), FIRST_NAME: string, LAST_NAME: string, BIRTH_DATE: timestamp, GENDER: decimal(38,10), EMAIL: string, STATUS: decimal(38,10), PHONE_NUMBER: string, LAST_MODIFICATION_DATE: timestamp]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "# Clean Dataframe After Use\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45817e-3ed4-4b6b-8d38-cc2cc9b957dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "%stop_session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v3]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
